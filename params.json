{
  "name": "DaymetR",
  "tagline": "a Daymet R package",
  "body": "# DaymetR\r\n\r\nThe DaymetR R package provides functions to (batch) download single pixel or gridded [Daymet data](http://daymet.ornl.gov/) (tiled) data directly into your R workspace, or save them as csv/tif files on your computer. Both a batch version as a single download version are provided. Gridded (tiled) data downloads for a region of interest are specified by a top left / bottom right coordinate pair or a single pixel location.\r\n\r\n## Installation\r\n\r\nclone the project to your home computer using the following command (with git installed)\r\n\r\n```R\r\nrequire(devtools)\r\ninstall_github(\"khufkens/daymetr\") # install the package\r\nrequire(DaymetR) # load the package\r\n```\r\n\r\n## Use\r\n\r\n### Single pixel location download\r\n\r\nFor a single site use the following format\r\n\r\n```R\r\n download.daymet(site=\"Oak Ridge National Laboratories\",lat=36.0133,lon=-84.2625,start_yr=1980,end_yr=2010,internal=TRUE)\r\n```\r\n\r\nParameter     | Description                      \r\n------------- | ------------------------------ \t\r\nsite\t      | site name\r\nlat           | latitude of the site\r\nlon           | longitude of the site\r\nstart_yr      | start year of the time series (data start in 1980)\r\nend_yr        | end year of the time series (current year - 2 years / for safety, tweak this check to reflect the currently available data)\r\ninternal      | logical, TRUE or FALSE, if true data is imported into R workspace otherwise it is downloaded into the current working directory\r\n\r\nBatch mode uses similar parameters but you provide a comma separated file with site names and latitude longitude which are sequentially downloaded. Format of the comma separated file is as such: site name, latitude, longitude.\r\n\r\n```R\r\nbatch.download.daymet(file_location='my_sites.csv',start_yr=1980,end_yr=2010,internal=TRUE)\r\n```\r\n\r\n### Gridded data download\r\n\r\nFor gridded data use the following format\r\n\r\n```R\r\ndownload.daymet.tiles(lat1=36.0133,lon1=-84.2625,lat2=NA,lon2=NA,start_yr=1980,end_yr=2012,param=\"ALL\")\r\n```\r\n\r\nParameter     | Description                      \r\n------------- | ------------------------------ \t\r\nlat1\t      | top left latitude\r\nlon1          | top left longitude\r\nlat2          | bottom right latitude\r\nlon2\t      | bottom right latitude\r\nstart_yr      | start year of the time series (data start in 1980)\r\nend_yr        | end year of the time series (current year - 2 years / for safety, tweak this check to reflect the currently available data)\r\nparam         | climate variable you want to download vapour pressure (vp), minimum and maximum temperature (tmin,tmax), snow water equivalent (swe), solar radiation (srad), precipitation (prcp) , day length (dayl). The default setting is ALL, this will download all the previously mentioned climate variables.\r\n\r\nIf only the first set of coordinates is provided the tile in which these reside is downloaded. If your region of interest falls outside the scope of the DAYMET data coverage a warning is issued. If both top left and bottom right coordinates are provided all tiles covering the region of interst are downloaded.\r\n\r\n## Notes\r\n\r\nFurthermore, the below code (bash script) allows you to convert [the ancillary DAYMET data](https://daymet.ornl.gov/files/ancillary_files.tgz) to a latitude / longitude format for further and easy processing. Although this is not an integral part of the DaymetR package it might prove useful in subsequent analysis. The R equivalent of this code will be up shortly.\r\n\r\n```bash\r\n#!/bin/bash\r\n\r\n# get filename with no extension\r\nno_extension=`basename $1 | cut -d'.' -f1`\r\n\r\n# convert the netCDF file to an ascii file\r\ngdal_translate -of AAIGrid $1 original.asc\r\n\r\n# extract the data with no header\r\ntail -n +7 original.asc > ascii_data.asc\r\n\r\n# paste everything together again with a correct header\r\necho \"ncols        8011\" \t>  final_ascii_data.asc\r\necho \"nrows        8220\"\t>> final_ascii_data.asc\r\necho \"xllcorner    -4659000.0\" \t>> final_ascii_data.asc\r\necho \"yllcorner    -3135000.0\" \t>> final_ascii_data.asc\r\necho \"cellsize     1000\" \t>> final_ascii_data.asc\r\necho \"NODATA_value 0\"    \t>> final_ascii_data.asc\r\n\r\n# append flipped data\r\ntac ascii_data.asc >> final_ascii_data.asc\r\n\r\n# translate the data into Lambert Conformal Conic GTiff\r\ngdal_translate -of GTiff -a_srs \"+proj=lcc +datum=WGS84 +lat_1=25 n +lat_2=60n +lat_0=42.5n +lon_0=100w\" final_ascii_data.asc tmp.tif\r\n\r\n# convert to latitude / longitude\r\ngdalwarp -of GTiff -overwrite -tr 0.009 0.009 -t_srs \"EPSG:4326\" tmp.tif tmp_lat_lon.tif\r\n\r\n# crop to reduce file size / only cover the DAYMET tiles\r\ngdal_translate -a_nodata -9999 -projwin -131.487784581 52.5568285568 -51.8801911189 13.9151864748 tmp_lat_lon.tif $no_extension.tif\r\n\r\n# clean up\r\nrm original.asc\r\nrm ascii_data.asc\r\nrm final_ascii_data.asc\r\nrm tmp.tif\r\nrm tmp_lat_lon.tif\r\n```\r\n\r\n### Dependencies\r\n\r\nThe code depends on the following R packages: sp, rgeos, rgdal, downloader\r\n",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}